{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77T27Z1CoXed",
        "outputId": "0596c350-217f-4d3e-d991-9f241af0bc94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\21379\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "import cv2 \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "import pywt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn import preprocessing\n",
        "import seaborn as sns\n",
        "import pickle \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from seaborn import heatmap\n",
        "import tempfile\n",
        "from tensorflow import keras\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "import tensorflow as tf\n",
        "# import tensorflow_addons as tfa\n",
        "\n",
        "import os\n",
        "\n",
        "# try:\n",
        "#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "#     print('Device:', tpu.master())\n",
        "#     tf.config.experimental_connect_to_cluster(tpu)\n",
        "#     tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "# except:\n",
        "#     strategy = tf.distribute.get_strategy()\n",
        "# print('Number of replicas:', strategy.num_replicas_in_sync)\n",
        "    \n",
        "# print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nbr de class pheonix 63\n"
          ]
        }
      ],
      "source": [
        "# Creation de la data complete\n",
        "\n",
        "iitd = []   # , casia phonix, mmu\n",
        "Liitd = []     # , Lcasia,LPho,  Lmmu\n",
        "\n",
        "datasets = ['phoenix']   # 'iitd', 'casiaclean',\n",
        "start = [3]   # ,3,5\n",
        "data = [iitd]  # iitd, casia,\n",
        "labels = [Liitd]  # Liitd, Lcasia,\n",
        "\n",
        "for d, s, images, label in zip(datasets, start, data, labels ):\n",
        "    for root, dirr, imgs in os.walk(f'data/aug/{d}'):\n",
        "            for img in imgs:\n",
        "                if ((img.endswith('bmp')) or (img.endswith('png')) or (img.endswith('jpg'))) :\n",
        "                    path = os.path.join(root,img)  \n",
        "                    image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "                    images.append(image)\n",
        "                    label.append(f'{d[:4]}_{img[:s]}')\n",
        "\n",
        "LE = preprocessing.LabelEncoder()\n",
        "labels_id_iitd = list(LE.fit_transform(Liitd)) \n",
        "labels_dic_iitd = {k:v for k,v in zip(Liitd,labels_id_iitd)}\n",
        "                                                        \n",
        "iitd = np.array(iitd)\n",
        "labels_id_iitd = np.array(labels_id_iitd) \n",
        "\n",
        "print('nbr de class pheonix',max(labels_id_iitd))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## to check if data are balanced\n",
        "\n",
        "# f , n = np.unique(labels_id_casia, return_counts=True) \n",
        "# r = np.where(n < 20)[0]\n",
        "\n",
        "# for i in range(len(r)):\n",
        "#     print([k for (k,v) in labels_dic_casia.items() if v == r[i]])\n",
        "    \n",
        "# print(min(n))\n",
        "# print(max(n))\n",
        "# sns.set(rc={'figure.figsize':(25,10)})\n",
        "# sns.countplot(labels_id_casia, color='red')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # # to balance classes \n",
        "# data_bal=[]\n",
        "# labels_bal=[]\n",
        "# for i,j in zip(labels_id_casia,casia) :\n",
        "#     if (labels_bal.count(i)<20):\n",
        "#         data_bal.append(j)\n",
        "#         labels_bal.append(i)\n",
        "        \n",
        "# labels_id22 = list(LE.fit_transform(labels_bal))\n",
        "\n",
        "# num_classes = max(labels_id22)+1\n",
        "# print(f'nbr of classes is {num_classes}')    \n",
        "# print(len(data_bal))     \n",
        "# f, n = np.unique(labels_bal, return_counts=True)\n",
        "# plt.figure(figsize=(25,10))\n",
        "# plt.plot(f,n)\n",
        "# plt.show()\n",
        "# print(min(n))   \n",
        "# data_bal = np.array(data_bal)\n",
        "# labels_id22 = np.array(labels_id22) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5Za1Zwsw-00z"
      },
      "outputs": [],
      "source": [
        "xtr, xts, ytr, yts = train_test_split(iitd,labels_id_iitd, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7fMJUo3DI4S"
      },
      "outputs": [],
      "source": [
        "# dynamic learning rate\n",
        "def exponential_decay(lr0, s):     # i need to search what is s and wch kayen type of learning rate schedulers mais mzl i didnt use it yet hada but fhamt wch aw sari.\n",
        "    def exponential_decay_fn(epoch):       # this is an inner function, 3ndhom many uses hado such as : encapsulation and preserve the inner function from ga3 wch ysra bara l outter function\n",
        "        return lr0 **(epoch / s)\n",
        "    return exponential_decay_fn\n",
        "\n",
        "exponential_decay_fn = exponential_decay(0.01, 10)\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)   # callbacks : fct li they take as argument other functions\n",
        "\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('val_acc') > 0.99:\n",
        "            print(\"\\nReached accuracy threshold! Terminating training.\")\n",
        "            self.model.stop_training = True\n",
        "            \n",
        "my_callback = MyCallback()\n",
        "\n",
        "#EarlyStopping callback to make sure model is always learning\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 30, 30, 96)        11712     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 15, 15, 96)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " zero_padding2d_6 (ZeroPaddi  (None, 19, 19, 96)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 17, 17, 16)        13840     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 8, 8, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " zero_padding2d_7 (ZeroPaddi  (None, 10, 10, 16)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 6, 6, 8)           3208      \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 3, 3, 8)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 72)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 4096)              299008    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 2048)              8390656   \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 64)                131136    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,849,560\n",
            "Trainable params: 8,849,560\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "CNN = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(128,128,1)),\n",
        "    tf.keras.layers.Conv2D(96, (11,11), strides = (4,4), activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.ZeroPadding2D(padding= (2,2)),\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.ZeroPadding2D(padding= (1,1)),\n",
        "    tf.keras.layers.Conv2D(8, (5, 5), activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(2048, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='softmax')\n",
        "                            ])\n",
        "CNN.compile( optimizer='adam', loss=\"sparse_categorical_crossentropy\",  metrics= 'accuracy')\n",
        "CNN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "96/96 [==============================] - 34s 290ms/step - loss: 5.5558 - accuracy: 0.0039 - val_loss: 5.2875 - val_accuracy: 0.0149\n",
            "Epoch 2/32\n",
            "96/96 [==============================] - 28s 289ms/step - loss: 5.1807 - accuracy: 0.0246 - val_loss: 5.0828 - val_accuracy: 0.0260\n",
            "Epoch 3/32\n",
            "96/96 [==============================] - 28s 291ms/step - loss: 4.8032 - accuracy: 0.0489 - val_loss: 4.6413 - val_accuracy: 0.0706\n",
            "Epoch 4/32\n",
            "96/96 [==============================] - 27s 285ms/step - loss: 4.2190 - accuracy: 0.0965 - val_loss: 3.7186 - val_accuracy: 0.1580\n",
            "Epoch 5/32\n",
            "96/96 [==============================] - 27s 286ms/step - loss: 3.5585 - accuracy: 0.1743 - val_loss: 3.4525 - val_accuracy: 0.2026\n",
            "Epoch 6/32\n",
            "96/96 [==============================] - 27s 286ms/step - loss: 2.9329 - accuracy: 0.2764 - val_loss: 2.8333 - val_accuracy: 0.3104\n",
            "Epoch 7/32\n",
            "96/96 [==============================] - 27s 286ms/step - loss: 2.4521 - accuracy: 0.3743 - val_loss: 2.2968 - val_accuracy: 0.4145\n",
            "Epoch 8/32\n",
            "96/96 [==============================] - 28s 287ms/step - loss: 1.9913 - accuracy: 0.4708 - val_loss: 1.9406 - val_accuracy: 0.4870\n",
            "Epoch 9/32\n",
            "96/96 [==============================] - 28s 291ms/step - loss: 1.6808 - accuracy: 0.5443 - val_loss: 1.7849 - val_accuracy: 0.5446\n",
            "Epoch 10/32\n",
            "96/96 [==============================] - 28s 288ms/step - loss: 1.4189 - accuracy: 0.5978 - val_loss: 1.5223 - val_accuracy: 0.5911\n",
            "Epoch 11/32\n",
            "96/96 [==============================] - 28s 293ms/step - loss: 1.2670 - accuracy: 0.6490 - val_loss: 1.3252 - val_accuracy: 0.6654\n",
            "Epoch 12/32\n",
            "96/96 [==============================] - 27s 284ms/step - loss: 0.9946 - accuracy: 0.7091 - val_loss: 1.3788 - val_accuracy: 0.6357\n",
            "Epoch 13/32\n",
            "96/96 [==============================] - 27s 281ms/step - loss: 0.8960 - accuracy: 0.7334 - val_loss: 1.1813 - val_accuracy: 0.6989\n",
            "Epoch 14/32\n",
            "96/96 [==============================] - 27s 282ms/step - loss: 0.7795 - accuracy: 0.7712 - val_loss: 1.2269 - val_accuracy: 0.6914\n",
            "Epoch 15/32\n",
            "96/96 [==============================] - 27s 280ms/step - loss: 0.6948 - accuracy: 0.7850 - val_loss: 1.1840 - val_accuracy: 0.7175\n",
            "Epoch 16/32\n",
            "96/96 [==============================] - 27s 280ms/step - loss: 0.6218 - accuracy: 0.8188 - val_loss: 1.0814 - val_accuracy: 0.7454\n",
            "Epoch 17/32\n",
            "96/96 [==============================] - 27s 280ms/step - loss: 0.5718 - accuracy: 0.8306 - val_loss: 1.1163 - val_accuracy: 0.7416\n",
            "Epoch 18/32\n",
            "96/96 [==============================] - 27s 279ms/step - loss: 0.4712 - accuracy: 0.8592 - val_loss: 1.0108 - val_accuracy: 0.7770\n",
            "Epoch 19/32\n",
            "96/96 [==============================] - 27s 283ms/step - loss: 0.5476 - accuracy: 0.8418 - val_loss: 1.1626 - val_accuracy: 0.7416\n",
            "Epoch 20/32\n",
            "96/96 [==============================] - 27s 283ms/step - loss: 0.5041 - accuracy: 0.8621 - val_loss: 1.2297 - val_accuracy: 0.7305\n",
            "Epoch 21/32\n",
            "96/96 [==============================] - 27s 285ms/step - loss: 0.4955 - accuracy: 0.8506 - val_loss: 0.9064 - val_accuracy: 0.7993\n",
            "Epoch 22/32\n",
            "96/96 [==============================] - 28s 288ms/step - loss: 0.4042 - accuracy: 0.8867 - val_loss: 0.9013 - val_accuracy: 0.7862\n",
            "Epoch 23/32\n",
            "96/96 [==============================] - 27s 280ms/step - loss: 0.3581 - accuracy: 0.8979 - val_loss: 0.9614 - val_accuracy: 0.7955\n",
            "Epoch 24/32\n",
            "96/96 [==============================] - 27s 282ms/step - loss: 0.2596 - accuracy: 0.9133 - val_loss: 0.9904 - val_accuracy: 0.8123\n",
            "Epoch 25/32\n",
            "96/96 [==============================] - 27s 284ms/step - loss: 0.3207 - accuracy: 0.9048 - val_loss: 1.2064 - val_accuracy: 0.7714\n",
            "Epoch 26/32\n",
            "96/96 [==============================] - 27s 281ms/step - loss: 0.3262 - accuracy: 0.9107 - val_loss: 1.1184 - val_accuracy: 0.7807\n",
            "Epoch 27/32\n",
            "96/96 [==============================] - 27s 281ms/step - loss: 0.2899 - accuracy: 0.9107 - val_loss: 1.0453 - val_accuracy: 0.7918\n",
            "Epoch 28/32\n",
            "96/96 [==============================] - 27s 286ms/step - loss: 0.2868 - accuracy: 0.9163 - val_loss: 0.9708 - val_accuracy: 0.7844\n",
            "Epoch 29/32\n",
            "96/96 [==============================] - 28s 293ms/step - loss: 0.3019 - accuracy: 0.9068 - val_loss: 1.0931 - val_accuracy: 0.7881\n",
            "Epoch 30/32\n",
            "96/96 [==============================] - 29s 297ms/step - loss: 0.3055 - accuracy: 0.9110 - val_loss: 1.1271 - val_accuracy: 0.7862\n",
            "Epoch 31/32\n",
            "96/96 [==============================] - 28s 293ms/step - loss: 0.3115 - accuracy: 0.9084 - val_loss: 1.1200 - val_accuracy: 0.7900\n",
            "Epoch 32/32\n",
            "96/96 [==============================] - 28s 294ms/step - loss: 0.2945 - accuracy: 0.9209 - val_loss: 1.1514 - val_accuracy: 0.7788\n"
          ]
        }
      ],
      "source": [
        "# CNN training   (we need to do it ki b svm ki blach)\n",
        "history = CNN.fit(\n",
        "    xtr,ytr,\n",
        "    # batch_size = 32,\n",
        "    validation_split=0.15,      # xval necreyiha apres\n",
        "    # callbacks=[lr_scheduler, early_stopping],\n",
        "    epochs=32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "Mi7peXswJfry",
        "outputId": "3c113497-880a-4061-9073-8773607cfe3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28/28 [==============================] - 1s 50ms/step - loss: 1.2349 - accuracy: 0.7913\n"
          ]
        }
      ],
      "source": [
        "# loss, acc = CNN.evaluate(xts,yts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CNN.save('test.h5', save_format='h5')\n",
        "# test = tf.keras.saving.load_model('mmu_86_43_test_86_11_val_92_79_train.h5', compile=False) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CNN.save_weights('iitd_79_test.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x16749e55ca0>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CNN.load_weights('model_save/phonix/without_pruning/phonix_0-86test.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved baseline model to: C:\\Users\\21379\\AppData\\Local\\Temp\\tmp1qfk0urn.h5\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# _, keras_file = tempfile.mkstemp('.h5')\n",
        "# tf.keras.models.save_model(CNN, keras_file, include_optimizer=False)\n",
        "# print('Saved baseline model to:', keras_file)\n",
        "\n",
        "\n",
        "# hadi it saves bsh i didnt try yet to load the model ysma idk wila i ll have the same problem as model.save wla lala"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_conv2d_  (None, 30, 30, 96)       23330     \n",
            " 9 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_max_poo  (None, 15, 15, 96)       1         \n",
            " ling2d_9 (PruneLowMagnitude                                     \n",
            " )                                                               \n",
            "                                                                 \n",
            " prune_low_magnitude_zero_pa  (None, 19, 19, 96)       1         \n",
            " dding2d_6 (PruneLowMagnitud                                     \n",
            " e)                                                              \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d_  (None, 17, 17, 16)       27666     \n",
            " 10 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_max_poo  (None, 8, 8, 16)         1         \n",
            " ling2d_10 (PruneLowMagnitud                                     \n",
            " e)                                                              \n",
            "                                                                 \n",
            " prune_low_magnitude_zero_pa  (None, 10, 10, 16)       1         \n",
            " dding2d_7 (PruneLowMagnitud                                     \n",
            " e)                                                              \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d_  (None, 6, 6, 8)          6410      \n",
            " 11 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_max_poo  (None, 3, 3, 8)          1         \n",
            " ling2d_11 (PruneLowMagnitud                                     \n",
            " e)                                                              \n",
            "                                                                 \n",
            " prune_low_magnitude_flatten  (None, 72)               1         \n",
            " _3 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_9  (None, 4096)             593922    \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            " prune_low_magnitude_dropout  (None, 4096)             1         \n",
            " _6 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_1  (None, 2048)             16779266  \n",
            " 0 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_dropout  (None, 2048)             1         \n",
            " _7 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_1  (None, 64)               262210    \n",
            " 1 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,692,812\n",
            "Trainable params: 8,849,560\n",
            "Non-trainable params: 8,843,252\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Compute end step to finish pruning after 32 epochs.  (hanseyi 32 kima f training ta3 without pruning)\n",
        "\n",
        "validation_split = 0.15 \n",
        "num_images = xtr.shape[0] * (1 - validation_split)\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0\n",
        "                                                               ,end_step=np.ceil(num_images).astype(np.int32))\n",
        "}\n",
        "\n",
        "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(CNN, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "model_for_pruning.load_weights('model_save/phonix/with_pruning/phonix_86_wella_93-76_with_pruned_model_wow.model')\n",
        "model_for_pruning.summary()\n",
        "\n",
        "# after compiling this li n9dro ndiro i believe load weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\21379\\anaconda3\\lib\\site-packages\\keras\\backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 27s 325ms/step - loss: 4.4785 - accuracy: 0.0247 - val_loss: 3.9769 - val_accuracy: 0.0430\n",
            "Epoch 2/32\n",
            "50/50 [==============================] - 21s 411ms/step - loss: 3.7704 - accuracy: 0.0728 - val_loss: 3.8915 - val_accuracy: 0.0932\n",
            "Epoch 3/32\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 3.4494 - accuracy: 0.1373 - val_loss: 3.1384 - val_accuracy: 0.1541\n",
            "Epoch 4/32\n",
            "50/50 [==============================] - 18s 358ms/step - loss: 2.8848 - accuracy: 0.2297 - val_loss: 2.7788 - val_accuracy: 0.2115\n",
            "Epoch 5/32\n",
            "50/50 [==============================] - 16s 327ms/step - loss: 2.3739 - accuracy: 0.3639 - val_loss: 2.1063 - val_accuracy: 0.3978\n",
            "Epoch 6/32\n",
            "50/50 [==============================] - 18s 366ms/step - loss: 1.9536 - accuracy: 0.4285 - val_loss: 1.9653 - val_accuracy: 0.4552\n",
            "Epoch 7/32\n",
            "50/50 [==============================] - 15s 291ms/step - loss: 1.5842 - accuracy: 0.5278 - val_loss: 1.4151 - val_accuracy: 0.5950\n",
            "Epoch 8/32\n",
            "50/50 [==============================] - 17s 339ms/step - loss: 1.2532 - accuracy: 0.6253 - val_loss: 1.2832 - val_accuracy: 0.6308\n",
            "Epoch 9/32\n",
            "50/50 [==============================] - 15s 293ms/step - loss: 0.9756 - accuracy: 0.6956 - val_loss: 0.8556 - val_accuracy: 0.7491\n",
            "Epoch 10/32\n",
            "50/50 [==============================] - 17s 351ms/step - loss: 0.6726 - accuracy: 0.8013 - val_loss: 0.8845 - val_accuracy: 0.7455\n",
            "Epoch 11/32\n",
            "50/50 [==============================] - 15s 292ms/step - loss: 0.6299 - accuracy: 0.8133 - val_loss: 0.5684 - val_accuracy: 0.8172\n",
            "Epoch 12/32\n",
            "50/50 [==============================] - 18s 353ms/step - loss: 0.4900 - accuracy: 0.8506 - val_loss: 0.5468 - val_accuracy: 0.8351\n",
            "Epoch 13/32\n",
            "50/50 [==============================] - 15s 291ms/step - loss: 0.4015 - accuracy: 0.8829 - val_loss: 0.4086 - val_accuracy: 0.8961\n",
            "Epoch 14/32\n",
            "50/50 [==============================] - 17s 340ms/step - loss: 0.3040 - accuracy: 0.9108 - val_loss: 0.5788 - val_accuracy: 0.8566\n",
            "Epoch 15/32\n",
            "50/50 [==============================] - 15s 301ms/step - loss: 0.3379 - accuracy: 0.8987 - val_loss: 0.4350 - val_accuracy: 0.8781\n",
            "Epoch 16/32\n",
            "50/50 [==============================] - 19s 374ms/step - loss: 0.1949 - accuracy: 0.9424 - val_loss: 0.3354 - val_accuracy: 0.9140\n",
            "Epoch 17/32\n",
            "50/50 [==============================] - 15s 303ms/step - loss: 0.2349 - accuracy: 0.9272 - val_loss: 0.3625 - val_accuracy: 0.8996\n",
            "Epoch 18/32\n",
            "50/50 [==============================] - 18s 352ms/step - loss: 0.1508 - accuracy: 0.9576 - val_loss: 0.2663 - val_accuracy: 0.9211\n",
            "Epoch 19/32\n",
            "50/50 [==============================] - 15s 304ms/step - loss: 0.1755 - accuracy: 0.9506 - val_loss: 0.3011 - val_accuracy: 0.9176\n",
            "Epoch 20/32\n",
            "50/50 [==============================] - 17s 347ms/step - loss: 0.1378 - accuracy: 0.9639 - val_loss: 0.3472 - val_accuracy: 0.9211\n",
            "Epoch 21/32\n",
            "50/50 [==============================] - 15s 302ms/step - loss: 0.1266 - accuracy: 0.9646 - val_loss: 0.2978 - val_accuracy: 0.9283\n",
            "Epoch 22/32\n",
            "50/50 [==============================] - 17s 346ms/step - loss: 0.1166 - accuracy: 0.9658 - val_loss: 0.3516 - val_accuracy: 0.9140\n",
            "Epoch 23/32\n",
            "50/50 [==============================] - 15s 305ms/step - loss: 0.1464 - accuracy: 0.9563 - val_loss: 0.2610 - val_accuracy: 0.9319\n",
            "Epoch 24/32\n",
            "50/50 [==============================] - 17s 349ms/step - loss: 0.1010 - accuracy: 0.9658 - val_loss: 0.2933 - val_accuracy: 0.9283\n",
            "Epoch 25/32\n",
            "50/50 [==============================] - 15s 309ms/step - loss: 0.0925 - accuracy: 0.9709 - val_loss: 0.2571 - val_accuracy: 0.9391\n",
            "Epoch 26/32\n",
            "50/50 [==============================] - 18s 350ms/step - loss: 0.0892 - accuracy: 0.9715 - val_loss: 0.3274 - val_accuracy: 0.9211\n",
            "Epoch 27/32\n",
            "50/50 [==============================] - 15s 305ms/step - loss: 0.0837 - accuracy: 0.9753 - val_loss: 0.2028 - val_accuracy: 0.9355\n",
            "Epoch 28/32\n",
            "50/50 [==============================] - 18s 352ms/step - loss: 0.0740 - accuracy: 0.9810 - val_loss: 0.2119 - val_accuracy: 0.9427\n",
            "Epoch 29/32\n",
            "50/50 [==============================] - 17s 348ms/step - loss: 0.0620 - accuracy: 0.9810 - val_loss: 0.1824 - val_accuracy: 0.9642\n",
            "Epoch 30/32\n",
            "50/50 [==============================] - 18s 352ms/step - loss: 0.0591 - accuracy: 0.9797 - val_loss: 0.2523 - val_accuracy: 0.9391\n",
            "Epoch 31/32\n",
            "50/50 [==============================] - 15s 307ms/step - loss: 0.0449 - accuracy: 0.9848 - val_loss: 0.3376 - val_accuracy: 0.9319\n",
            "Epoch 32/32\n",
            "50/50 [==============================] - 16s 318ms/step - loss: 0.0499 - accuracy: 0.9854 - val_loss: 0.3143 - val_accuracy: 0.9319\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1674d540d30>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# traning with pruning (before saving the weights hadi)\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "model_for_pruning.fit(xtr, ytr,\n",
        "                  epochs= 32,\n",
        "                  validation_split=validation_split,\n",
        "                  callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\21379\\anaconda3\\lib\\site-packages\\keras\\backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 2s 70ms/step - loss: 0.3388 - accuracy: 0.9376\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model_for_pruning.evaluate(xts, yts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model_for_pruning.save_weights('phonix_86_wella_93-76_with_pruned_model_wow.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # cross validation bsh 9er3a for computer vision\n",
        "\n",
        "# num_classes = 44\n",
        "# def CNN () :\n",
        "#     CNN = tf.keras.models.Sequential([\n",
        "#         tf.keras.layers.Input(shape=(128,128,1)),\n",
        "#         tf.keras.layers.Conv2D(96, (11,11), strides = (4,4), activation='relu'),\n",
        "#         tf.keras.layers.MaxPool2D(),\n",
        "#         tf.keras.layers.ZeroPadding2D(padding= (2,2)),\n",
        "#         tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "#         tf.keras.layers.MaxPool2D(),\n",
        "#         tf.keras.layers.ZeroPadding2D(padding= (1,1)),\n",
        "#         tf.keras.layers.Conv2D(8, (5, 5), activation='relu'),\n",
        "#         tf.keras.layers.MaxPool2D(),\n",
        "#         tf.keras.layers.Flatten(),\n",
        "#         tf.keras.layers.Dense(4096, activation='relu'),\n",
        "#         tf.keras.layers.Dropout(0.5),\n",
        "#         tf.keras.layers.Dense(2048, activation='relu'),\n",
        "#         tf.keras.layers.Dropout(0.5),\n",
        "#         tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "#                                 ])\n",
        "#     CNN.compile( optimizer='adam', loss=\"sparse_categorical_crossentropy\",  metrics= 'accuracy')\n",
        "#     return CNN\n",
        "\n",
        "# # tfa.metrics.F1Score(num_classes= 44, average='micro')\n",
        "# # CNN.summary()\n",
        "\n",
        "# def display_cv_results(search_results):\n",
        "#     print('Best score = {:.4f} using {}'.format(search_results.best_score_, search_results.best_params_))\n",
        "#     means = search_results.cv_results_['mean_test_score']\n",
        "#     stds = search_results.cv_results_['std_test_score']\n",
        "#     params = search_results.cv_results_['params']\n",
        "#     for mean, stdev, param in zip(means, stds, params):\n",
        "#         print('mean test accuracy +/- std = {:.4f} +/- {:.4f} with: {}'.format(mean, stdev, param)) \n",
        "        \n",
        "# from sklearn.model_selection import KFold\n",
        "\n",
        "# kfold = KFold(n_splits=5, shuffle=True)\n",
        "# model = KerasClassifier(build_fn=CNN)\n",
        "# param_grid = {\n",
        "#     'batch_size': [16, 32, 64],\n",
        "#     'epochs': [20,30,40],\n",
        "# }\n",
        "\n",
        "# grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring = 'accuracy', cv=kfold)\n",
        "# grid_result = grid.fit(mmu,labels_id_mmu)  # fit the full dataset as we are using cross validation \n",
        "\n",
        "# display_cv_results(grid_result)   \n",
        "\n",
        "# # cross val b sklearn\n",
        "# from sklearn.model_selection import cross_validate\n",
        "\n",
        "# _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
        "# results = cross_validate(estimator=CNN,\n",
        "#                                X=xtr,\n",
        "#                                y=ytr,\n",
        "#                                cv= 5,\n",
        "#                                scoring=_scoring,\n",
        "#                                return_train_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcyDMz72yrqb",
        "outputId": "83733761-89ea-4a70-a2f8-568a4aaed2b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " prune_low_magnitude_conv2d_  (None, 30, 30, 96)       23330     \n",
            " 9 (PruneLowMagnitude)                                           \n",
            "                                                                 \n",
            " prune_low_magnitude_max_poo  (None, 15, 15, 96)       1         \n",
            " ling2d_9 (PruneLowMagnitude                                     \n",
            " )                                                               \n",
            "                                                                 \n",
            " prune_low_magnitude_zero_pa  (None, 19, 19, 96)       1         \n",
            " dding2d_6 (PruneLowMagnitud                                     \n",
            " e)                                                              \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d_  (None, 17, 17, 16)       27666     \n",
            " 10 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_max_poo  (None, 8, 8, 16)         1         \n",
            " ling2d_10 (PruneLowMagnitud                                     \n",
            " e)                                                              \n",
            "                                                                 \n",
            " prune_low_magnitude_zero_pa  (None, 10, 10, 16)       1         \n",
            " dding2d_7 (PruneLowMagnitud                                     \n",
            " e)                                                              \n",
            "                                                                 \n",
            " prune_low_magnitude_conv2d_  (None, 6, 6, 8)          6410      \n",
            " 11 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_max_poo  (None, 3, 3, 8)          1         \n",
            " ling2d_11 (PruneLowMagnitud                                     \n",
            " e)                                                              \n",
            "                                                                 \n",
            " prune_low_magnitude_flatten  (None, 72)               1         \n",
            " _3 (PruneLowMagnitude)                                          \n",
            "                                                                 \n",
            " prune_low_magnitude_dense_9  (None, 4096)             593922    \n",
            "  (PruneLowMagnitude)                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 651,334\n",
            "Trainable params: 327,768\n",
            "Non-trainable params: 323,566\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_for_pruning.pop() # it will remove the last layer\n",
        "model_for_pruning.summary() # check the network "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_6qXLupu09Cq"
      },
      "outputs": [],
      "source": [
        "# feature extraction with wavelet\n",
        "\n",
        "WaveletTrain = []\n",
        "WaveletTest = []\n",
        "\n",
        "for i in range(len(xtr)):\n",
        "  LLtr = pywt.dwt2(xtr[i], 'bior2.2' )[0].astype('uint8')\n",
        "  LLtr = np.reshape( LLtr , (LLtr.shape[0]*LLtr.shape[1],))\n",
        "  WaveletTrain.append(LLtr) \n",
        "\n",
        "for k in range(len(xts)):\n",
        "  LLts = pywt.dwt2(xts[k], 'bior2.2' )[0].astype('uint8')\n",
        "  LLts = np.reshape( LLts , (LLts.shape[0]*LLts.shape[1],))\n",
        "  WaveletTest.append(LLts)\n",
        " \n",
        "WTr_feat = np.array(WaveletTrain)\n",
        "WTs_feat = np.array(WaveletTest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v6jskjK30VU",
        "outputId": "5182c3a2-7a00-494f-d248-c92c9913757a"
      },
      "outputs": [],
      "source": [
        "WTr_feat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "kernel = cv2.getGaborKernel( ksize= (5,5) , sigma= 1 ,theta= 0,lambd= 1*np.pi/4 ,gamma= 0, psi= 0)\n",
        "Gabor = cv2.filter2D(image,-1, kernel= kernel)\n",
        "\n",
        "# feature extraction with wavelet\n",
        "\n",
        "GaborTrain = []\n",
        "GaborTest = []\n",
        "\n",
        "for i in range(len(xtr)):\n",
        "  gabtr = cv2.filter2D(xtr[i],-1, kernel= kernel)\n",
        "  gabtr = np.reshape( gabtr , (gabtr.shape[0]*gabtr.shape[1],))\n",
        "  GaborTrain.append(gabtr) \n",
        "\n",
        "for k in range(len(xts)):\n",
        "  gabts = cv2.filter2D(xts[k],-1, kernel= kernel)\n",
        "  gabts = np.reshape( gabts , (gabts.shape[0]*gabts.shape[1],))\n",
        "  GaborTest.append(gabts)\n",
        " \n",
        "GTr_feat = np.array(GaborTrain)\n",
        "GTs_feat = np.array(GaborTest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "yYuotOcXytNJ"
      },
      "outputs": [],
      "source": [
        "CNN_train_feat = model_for_pruning(xtr)      # tmed vecteur fih 751 lignes (nbr des images) et chaque lignes c l features \n",
        "CNN_test_feat = model_for_pruning(xts)\n",
        "\n",
        "train_feat_W = np.hstack((CNN_train_feat, WTr_feat))    # Wtr c features men wavelat jayin de la forme  tan chaque ligne image, aya donc nconcateniw horzotalement bch yjona ga3 l features\n",
        "test_feat_W = np.hstack((CNN_test_feat, WTs_feat))\n",
        "\n",
        "train_feat_G = np.hstack((CNN_train_feat, GTr_feat))    # Wtr c features men wavelat jayin de la forme  tan chaque ligne image, aya donc nconcateniw horzotalement bch yjona ga3 l features\n",
        "test_feat_G = np.hstack((CNN_test_feat, GTs_feat))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFylLYvs5tyU",
        "outputId": "741c63f9-d4a7-4241-b632-8244f2321b8e"
      },
      "outputs": [],
      "source": [
        "print(train_feat_G.shape)\n",
        "print(ytr.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "KGCb7Ae442EO"
      },
      "outputs": [],
      "source": [
        "clf = SVC()\n",
        "clf.fit(CNN_train_feat, ytr)\n",
        "pred = clf.predict(CNN_test_feat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to save svm model\n",
        "filename = 'one_dense_svm_phonix_with_pruning_91.sav'\n",
        "pickle.dump(clf, open(filename, 'wb'))\n",
        "# test = pickle.load(open(filename, 'rb'))\n",
        "# result = test.score(CNN_test_feat, yts)\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ODkvY1O6fm0Y"
      },
      "outputs": [],
      "source": [
        "clf_W = SVC()\n",
        "clf_W.fit(train_feat_W, ytr)\n",
        "pred_W = clf_W.predict(test_feat_W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_G = SVC()\n",
        "clf_G.fit(train_feat_G, ytr)\n",
        "pred_G = clf_G.predict(test_feat_G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "iTczqx0pz5W9",
        "outputId": "6721a66d-ff9a-47b3-a3df-303001d38d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy :  0.9161290322580645\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm = confusion_matrix(yts,pred)\n",
        "heatmap(cm)\n",
        "\n",
        "accuracy = float(cm.diagonal().sum())/len(yts)\n",
        "print(\"Accuracy : \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy :  0.8172043010752689\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cmW = confusion_matrix(yts,pred_W)\n",
        "heatmap(cmW)\n",
        "\n",
        "accuracyW = float(cmW.diagonal().sum())/len(yts)\n",
        "print(\"Accuracy : \", accuracyW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy :  0.8838709677419355\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cmG = confusion_matrix(yts,pred_G)\n",
        "heatmap(cmG)\n",
        "\n",
        "accuracyG = float(cmG.diagonal().sum())/len(yts)\n",
        "print(\"Accuracy : \", accuracyG)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LEnY27nPJYMI"
      },
      "source": [
        "## 1st try with mixed datasets \n",
        "Results : EPOCHS = 20\n",
        "- CNN pure : acc = 0.40 (0.28)\n",
        "- CNN brk + svm (sans dense) : acc = 0.367\n",
        "- 2 dense (4000 + 2000 ) + svm : acc = 0.44  (0.01)\n",
        "- 1 dense (4000) + svm : acc = 0.61\n",
        "\n",
        "- 2 dense + wavelet + svm : acc = 0.005319148936170213\n",
        "- 1 dense + wavelet + svm : acc = 0.015957446808510637\n",
        "\n",
        "Conclusion : mafihach wavelet for feature extraction\n",
        "i think we need ndiro cross validation psk kolma ybdl chwiya fhadak train testsplit ytbdl l resultat bzaaaaf ..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2nd try with seperate datasets :\n",
        "IITD :  20 / 32 epochs\n",
        "- CNN pure : train : 85.85   test 78.79  / train:  0.9443 val: 0.8961  test: 0.9011    \n",
        " train:  0.9209 val: 0.7788  test: 0.7913    \n",
        "\n",
        "- CNN 2 dense + svm : 0.7701 / 0.7879464285714286 (with cnn 79)\n",
        "- CNN 2 dense + wavelet + svm : 0.3103 / 0.32142857142857145\n",
        "- CNN 2 dense + Gabor + svm : 0.7031 / 0.6752232142857143\n",
        "\n",
        "- CNN 1 dense + svm : 0.7824 /  0.8493303571428571\n",
        "- CNN 1 dense + wavelet + svm : 0.2422 / 0.28013392857142855\n",
        "- CNN 1 dense + Gabor + svm : 0.6920 / 0.6674107142857143\n",
        "\n",
        "- CNN 0 dense + svm : 0.7545 / 0.8203125\n",
        "- CNN 0 dense + wavelet + svm : 0.375 / 0.3638392857142857\n",
        "- CNN 0 dense + Gabor + svm : 0.7154 / 0.6774553571428571\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "mmu : 20 / 32 epochs\n",
        "\n",
        "- CNN pure train : 0.8292 , test : 0.7786   / train 0.9013, val 0.7460, test : 0.7405\n",
        "\n",
        "- CNN 2 dense + svm : 0.8428571428571429  / 0.7214\n",
        "- CNN 2 dense + wavelet + svm : 0.75     / 0.7523\n",
        "- CNN 2 dense + Gabor + svm : 0.7309     / 0.6976\n",
        "\n",
        "- CNN 1 dense + svm : 0.8142857142857143   /   0.6785714285714286\n",
        "- CNN 1 dense + wavelet + svm : 0.7095238095238096 /  0.7071428571428572\n",
        "- CNN 1 dense + Gabor + svm : 0.7 / 0.6547619047619048\n",
        "\n",
        "- CNN 0 dense + svm : 0.6095238095238096\n",
        "- CNN 0 dense + wavelet + svm : 0.8333333333333334\n",
        "- CNN 0 dense + Gabor + svm : 0.7428571428571429\n",
        "\n",
        "why wavelet on mmu better than wavelet on iitd :\n",
        "iitd fiha bzf variations and wavelet ynahi l high freq qhich means ya3mi bzf l image and ynahi l texture so machi\n",
        "adapt l images lifihom high variations kima iitdm par contre gabor non. and that s why fl cas ta3 mmu both mchaw bien, \n",
        "ps mmu les images jayin homogenes, like mafihomch variations bzf so wavelet maya3mihach fihom.\n",
        "\n",
        "\n",
        "\n",
        "casia :  (30 ep : 0.8763, test : 0.8201) (epochs 20 : train : 0.8318 test : 0.8044) \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "phonix : 32 epochs\n",
        "- CNN pure : train 0.9532  val 0.8817 test 0.8688\n",
        "\n",
        "- CNN 2 dense + svm : 0.9376344086021505\n",
        "- CNN 2 dense + wavelet + svm : 0.7935483870967742\n",
        "- CNN 2 dense + Gabor + svm : 0.8580645161290322\n",
        "\n",
        "- CNN 1 dense + svm : 0.7956989247311828\n",
        "- CNN 1 dense + wavelet + svm : 0.7827956989247312\n",
        "- CNN 1 dense + Gabor + svm : 0.8451612903225807\n",
        "\n",
        "- CNN 0 dense + svm : 0.6774193548387096\n",
        "- CNN 0 dense + wavelet + svm : 0.7956989247311828\n",
        "- CNN 0 dense + Gabor + svm : 0.875268817204301\n",
        "\n",
        "\n",
        "pheonix with pruning :\n",
        "\n",
        "- CNN pure : tr : 0.9854 val : 0.9319 ts : 0.9376 \n",
        "\n",
        "- CNN 2 dense + svm : 0.9225806451612903\n",
        "- CNN 2 dense + wavelet + svm : 0.7935483870967742\n",
        "- CNN 2 dense + Gabor + svm : 0.864516129032258\n",
        "\n",
        "- CNN 1 dense + svm : 0.9161290322580645\n",
        "- CNN 1 dense + wavelet + svm : 0.7784946236559139 \n",
        "- CNN 1 dense + Gabor + svm : 0.8559139784946237\n",
        "\n",
        "- CNN 0 dense + svm : 0.8903225806451613\n",
        "- CNN 0 dense + wavelet + svm : 0.8172043010752689\n",
        "- CNN 0 dense + Gabor + svm : 0.8838709677419355\n",
        "\n",
        "we may chose cnn 1 dense we lose 2% and we gain 8 millions de parametres.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
